template_info:
  create: 3 # number of experiments to create
  include_keys: ['model', 'optimizer', 'scheduler', 'audio_chunking', 'wandb', 'checkpointing', 'data', 'training'] #, 'sequence_scheduler'] # keys to include in experiments config
  template_keys: [
    'checkpointing.dir', 
    'wandb.name', 
    'optimizer.args.lr',
    'audio_chunking.size',
    'training.batch_size',
    'scheduler.warmup_steps',
  ] # keys to use to create experiments

model:
  feat_in: 80
  n_layers: 6
  d_model: 768
  n_heads: 6
  head_dim: 128
  dropout_ff: 0.0 # dropout parameters
  dropout_attn: 0.0
  dropout_conv: 0.0
  subsampling_factor: 4 # subsampling parameters
  subsampling: 'striding'
  subsampling_act: 'silu'
  subsampling_conv_channels: -1
  self_condition_subsampling: false
  subsampling_norm_out: false
  conv_kernel_size: 31
  qk_rms_norm: false 
  shift_kvs: false
  self_conditioning: true
  gated_sc: false
  decoder_norm: true
  use_rotary: true
  encoder_mode: 'conformer'
  default_norm: 'rms_norm'
  sandwich_norm: false
  bias_in_ff: false
  checkpoint_every_n_layers: 0
  grouped_attention: false

optimizer:
  name: 'madgrad'
  args:
    lr: [3e-3, 3e-3, 1e-3]

scheduler:
  warmup_steps: [6000, 9000, 9000]

audio_chunking: # 360000 (max = 1 hour)
  size: [
    1024,
    2048,
    4096
  ]
  overlap: 0 # not using currently...

# sequence_scheduler:
#   increase_every: 5000
#   stop_after: 90000
#   start_after: 0
#   max_sequence_length: [512, 1024, 2048, 4096, 8192, 512, 1024, 2048, 4096, 8192]
#   increase_by_multiplier: 2
#   batch_size_multiplier: 0.5
#   interpolate_rotary: false

wandb:
  use: true
  project_name: "spotify_long_context"
  name: [ 
    'ss4x_1024_3e3',
    'ss4x_2048_3e3',
    'ss4x_4096_1e3'
  ]
  id: "" # leave empty if not resuming a previous run

checkpointing:
  dir: [
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints/ss4x_1024_3e3',
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints/ss4x_2048_3e3',
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints/ss4x_4096_1e3'
  ]
  save_every_n_steps: 2000

# full data: #'/mnt/parscratch/users/acp21rjf/spotify/audio_txt_pairs.json'
# 25% of corpus: '/users/acp21rjf/long-context-asr/reduced_pairs.json'
data:
  path: '/mnt/parscratch/users/acp21rjf/spotify/audio_txt_pairs.json'
  
training:
  batch_size: [
    176,
    88,
    44,
  ]
  backprop_every: 2
  backwards_every: 1
  max_seq_len: 0
  clip_value: 0.8
  intermediate_loss_weighting: 0.0

# size: 512 = batch size 704
# size: 1024 = batch size 352
# size: 2048 = batch size 176
# size: 4096 = batch size 88
# size: 8192 = batch size 44
# size: 16384 = batch size 22
# size: 65536 = batch size 5 
# size: 131072 = batch size 2
# size: 360000 (1 hour) =  batch size 1