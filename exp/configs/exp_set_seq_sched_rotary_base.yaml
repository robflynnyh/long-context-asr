template_info:
  create: 12 # number of experiments to create
  include_keys: ['model', 'optimizer', 'scheduler', 'audio_chunking', 'wandb', 'checkpointing', 'data', 'training', 'sequence_scheduler'] # keys to include in experiments config
  template_keys: [
    'checkpointing.dir', 
    'wandb.name', 
    'sequence_scheduler.max_sequence_length',
    'model.rotary_base_freq',
  ] # keys to use to create experiments

model:
  feat_in: 80
  n_layers: 6
  d_model: 768
  n_heads: 6
  head_dim: 128
  dropout_ff: 0.0 # dropout parameters
  dropout_attn: 0.0
  dropout_conv: 0.0
  subsampling_factor: 8 # subsampling parameters
  subsampling: 'dw_striding'
  subsampling_act: 'silu'
  subsampling_conv_channels: 256
  self_condition_subsampling: false
  subsampling_norm_out: false
  conv_kernel_size: 9
  qk_rms_norm: false 
  shift_kvs: false
  self_conditioning: true
  gated_sc: false
  decoder_norm: true
  use_rotary: true
  encoder_mode: 'conformer'
  default_norm: 'layer_norm'
  sandwich_norm: false
  bias_in_ff: false
  checkpoint_every_n_layers: 0
  rotary_base_freq: [
    10000,
    100000,
    250000,
    500000,
    750000,
    1000000,
    1250000,
    1500000,
    1750000,
    2000000,
    3000000,
    4000000,
  ] # https://arxiv.org/pdf/2309.16039.pdf

optimizer:
  name: 'madgrad'
  args:
    lr: 3e-3

scheduler:
  warmup_steps: 1500

audio_chunking: # 360000 (max = 1 hour)
  size: 512
  overlap: 0 # not using currently...

sequence_scheduler:
  increase_every: 5000
  stop_after: 90000
  start_after: 0
  max_sequence_length: [
    65536, #1
    65536, #2
    65536, #3
    65536, #4
    65536, #5
    65536, #6
    65536, #7
    65536, #8
    65536, #9
    65536, #10
    65536, #11
    65536, #12
  ]
  increase_by_multiplier: 2
  batch_size_multiplier: 0.5
  interpolate_rotary: false

wandb:
  use: true
  project_name: "spotify_long_context"
  name: [ 
    'n_seq_sched_65536_freq_10000', #1
    'n_seq_sched_65536_freq_100000', #2
    'n_seq_sched_65536_freq_250000', #3
    'n_seq_sched_65536_freq_500000', #4
    'n_seq_sched_65536_freq_750000', #5
    'n_seq_sched_65536_freq_1000000', #6
    'n_seq_sched_65536_freq_1250000', #7
    'n_seq_sched_65536_freq_1500000', #8
    'n_seq_sched_65536_freq_1750000', #9
    'n_seq_sched_65536_freq_2000000', #10
    'n_seq_sched_65536_freq_3000000', #11
    'n_seq_sched_65536_freq_4000000', #12
  ]
  id: "" # leave empty if not resuming a previous run

checkpointing:
  dir: [
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints_seq_scheduler_rotarybase/n_seq_sched_65536_freq_10000', #1
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints_seq_scheduler_rotarybase/n_seq_sched_65536_freq_100000', #2
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints_seq_scheduler_rotarybase/n_seq_sched_65536_freq_250000', #3
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints_seq_scheduler_rotarybase/n_seq_sched_65536_freq_500000', #4
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints_seq_scheduler_rotarybase/n_seq_sched_65536_freq_750000', #5
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints_seq_scheduler_rotarybase/n_seq_sched_65536_freq_1000000', #6
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints_seq_scheduler_rotarybase/n_seq_sched_65536_freq_1250000', #7
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints_seq_scheduler_rotarybase/n_seq_sched_65536_freq_1500000', #8
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints_seq_scheduler_rotarybase/n_seq_sched_65536_freq_1750000', #9
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints_seq_scheduler_rotarybase/n_seq_sched_65536_freq_2000000', #10
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints_seq_scheduler_rotarybase/n_seq_sched_65536_freq_3000000', #11
    '/mnt/parscratch/users/acp21rjf/spotify/checkpoints_seq_scheduler_rotarybase/n_seq_sched_65536_freq_4000000', #12
  ]
  save_every_n_steps: 2000

# full data: #'/mnt/parscratch/users/acp21rjf/spotify/audio_txt_pairs.json'
# 25% of corpus: '/users/acp21rjf/long-context-asr/reduced_pairs.json'
data:
  path: '/mnt/parscratch/users/acp21rjf/spotify/audio_txt_pairs.json'
  
training:
  batch_size: 704
  backprop_every: 1
  backwards_every: 1
  max_seq_len: 0
  clip_value: 0.8
  intermediate_loss_weighting: 0.0
  random_seed: 33412

# size: 512 = batch size 704
# size: 1024 = batch size 352
# size: 2048 = batch size 176
# size: 4096 = batch size 88
# size: 8192 = batch size 44
# size: 16384 = batch size 22
# size: 65536 = batch size 5 
# size: 131072 = batch size 2
# size: 360000 (1 hour) =  batch size 1