
model:
  feat_in: 80
  n_layers: 6
  d_model: 768
  n_heads: 6
  head_dim: 128
  dropout_ff: 0.0
  dropout_attn: 0.0
  dropout_conv: 0.0
  checkpoint_every_n_layers: 0
  subsampling_factor: 8
  subsampling: 'dw_striding'
  subsampling_conv_channels: 256
  conv_kernel_size: 9
  qk_rms_norm: false
  shift_kvs: false
  self_conditioning: true
  gated_sc: false
  decoder_norm: true
  use_rotary: true
  encoder_mode: 'conformer'
  history_vector: false
  default_norm: 'layer_norm'


optimizer:
  name: 'madgrad'
  args:
    lr: 1e-4

scheduler:
  warmup_steps: 3000


audio_chunking: # 360000 (max = 1 hour)
  size: 512
  overlap: 0 # not using currently...

wandb:
  use: true
  project_name: "spotify_long_context"
  id: "" # leave empty if not resuming a previous run

checkpointing:
  dir: '/mnt/parscratch/users/acp21rjf/1e4_512'
  save_every_n_steps: 30

# full data: #'/mnt/parscratch/users/acp21rjf/spotify/audio_txt_pairs.json'
# 25% of corpus: '/users/acp21rjf/long-context-asr/reduced_pairs.json'
data:
  path: '/mnt/parscratch/users/acp21rjf/spotify/audio_txt_pairs.json'
  
training:
  batch_size: 352
  backprop_every: 2
  max_seq_len: 0 # max cache length

# size: 1024 = batch size 352
# size: 2048 = batch size 176
# size: 4096 = batch size 88
# size: 8192 = batch size 44
# size: 16384 = batch size 22
# size: 65536 = batch size 5 
# size: 131072 = batch size 2
# size: 360000 (1 hour) =  batch size 1